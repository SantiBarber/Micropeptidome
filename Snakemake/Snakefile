#############################################
# Snakefile: per-sample ShortStop workflow
# Uses: StringTie, TransDecoder, ShortStop
#
# Run:
#   conda activate snakemake
#   snakemake --use-conda --slurm -j 32
#
#  In the running directory there must be a config.yaml file, a GRCh38.primary_assembly.genome.fa and a gencode.v38.primary_assembly.annotation.gtf
#  Check the workflow.sh to see how to download the annotation and FASTA files.
#############################################

import glob
from pathlib import Path

configfile: "config.yaml"

# Absolute outdir avoids SLURM working-dir surprises
OUTDIR = str(Path(config["outdir"]).resolve())

# Find BAMs
BAMS = sorted(glob.glob(config["bam_glob"]))
if not BAMS:
    raise ValueError(f"No BAMs found. Check bam_glob: {config['bam_glob']}")

SAMPLES = [Path(b).parent.name for b in BAMS]

BAM_BY_SAMPLE = {}
for bam in BAMS:
    s = Path(bam).parent.name
    if s in BAM_BY_SAMPLE and BAM_BY_SAMPLE[s] != bam:
        raise ValueError(
            f"Multiple BAMs found for sample '{s}':\n  {BAM_BY_SAMPLE[s]}\n  {bam}\nFix bam_glob or naming."
        )
    BAM_BY_SAMPLE[s] = bam

def bam_path(wc):
    return BAM_BY_SAMPLE[wc.sample]

MERGED_DIR = config["merged_dir"]
COHORT_PREFIX = config["cohort_prefix"]
MIN_PATIENTS = int(config.get("min_patients", 2))

rule all:
    input:
        expand(f"{OUTDIR}/{{sample}}/shortstop/predict.done", sample=SAMPLES),
        expand(f"{MERGED_DIR}/{{sample}}.merged.csv", sample=SAMPLES),
        f"{COHORT_PREFIX}.all_loci.csv",
        f"{COHORT_PREFIX}.shared_ge{MIN_PATIENTS}.csv"


rule stringtie_assemble:
    input:
        bam=bam_path,
        ref_gtf=config["gencode_gtf"]
    output:
        gtf=f"{OUTDIR}/{{sample}}/stringtie/{{sample}}.gtf"
    threads: config.get("threads_stringtie", 8)
    resources:
        mem_mb=16000
    shell:
        r"""
        set -euo pipefail
        mkdir -p "{OUTDIR}/{wildcards.sample}/stringtie"

        conda run --no-capture-output -n smORFs stringtie "{input.bam}" \
          -G "{input.ref_gtf}" \
          -o "{output.gtf}" \
          -p {threads}
        """


rule gffread_transcripts:
    input:
        gtf=f"{OUTDIR}/{{sample}}/stringtie/{{sample}}.gtf",
        genome=config["genome_fa"]
    output:
        fa=f"{OUTDIR}/{{sample}}/transcripts/{{sample}}.transcripts.fa"
    threads: 1
    resources:
        mem_mb=8000
    shell:
        r"""
        set -euo pipefail
        mkdir -p "{OUTDIR}/{wildcards.sample}/transcripts"

        conda run --no-capture-output -n smORFs gffread "{input.gtf}" \
          -g "{input.genome}" \
          -w "{output.fa}"
        """


rule transdecoder_longorfs:
    input:
        fa=f"{OUTDIR}/{{sample}}/transcripts/{{sample}}.transcripts.fa"
    output:
        done=f"{OUTDIR}/{{sample}}/transdecoder/longorfs.done"
    threads: 1
    resources:
        mem_mb=16000
    shell:
        r"""
        set -euo pipefail
        mkdir -p "{OUTDIR}/{wildcards.sample}/transdecoder"

        # run inside transcripts dir so outputs land there, not in Workdir
        cd "{OUTDIR}/{wildcards.sample}/transcripts"
        conda run --no-capture-output -n smORFs TransDecoder.LongOrfs -t "{wildcards.sample}.transcripts.fa"

        touch "../transdecoder/longorfs.done"
        """


rule transdecoder_predict:
    input:
        fa=f"{OUTDIR}/{{sample}}/transcripts/{{sample}}.transcripts.fa",
        longorfs_done=f"{OUTDIR}/{{sample}}/transdecoder/longorfs.done"
    output:
        pep=f"{OUTDIR}/{{sample}}/transcripts/{{sample}}.transcripts.fa.transdecoder.pep",
        gff3=f"{OUTDIR}/{{sample}}/transcripts/{{sample}}.transcripts.fa.transdecoder.gff3"
    threads: 1
    resources:
        mem_mb=24000
    shell:
        r"""
        set -euo pipefail

        cd "{OUTDIR}/{wildcards.sample}/transcripts"
        conda run --no-capture-output -n smORFs TransDecoder.Predict -t "{wildcards.sample}.transcripts.fa"

        test -s "{wildcards.sample}.transcripts.fa.transdecoder.pep"
        test -s "{wildcards.sample}.transcripts.fa.transdecoder.gff3"
        """


rule filter_smorfs:
    input:
        pep=f"{OUTDIR}/{{sample}}/transcripts/{{sample}}.transcripts.fa.transdecoder.pep",
        gff3=f"{OUTDIR}/{{sample}}/transcripts/{{sample}}.transcripts.fa.transdecoder.gff3",
        script=config["filter_smorf_pep_py"]
    output:
        smorfs_fa=f"{OUTDIR}/{{sample}}/smorfs/{{sample}}.smorfs.fa",
        ids=f"{OUTDIR}/{{sample}}/smorfs/{{sample}}.smorf_ids.txt",
        smorfs_gff3=f"{OUTDIR}/{{sample}}/smorfs/{{sample}}.smorfs.gff3"
    threads: 1
    resources:
        mem_mb=8000
    shell:
        r"""
        set -euo pipefail
        mkdir -p "{OUTDIR}/{wildcards.sample}/smorfs"

        conda run --no-capture-output -n smORFs python "{input.script}" \
          "{input.pep}" \
          --min_len {config[min_aa]} \
          --max_len {config[max_aa]} \
          --out_fasta "{output.smorfs_fa}" \
          --out_ids "{output.ids}"

        grep -F -f "{output.ids}" "{input.gff3}" > "{output.smorfs_gff3}"

        test -s "{output.smorfs_fa}"
        test -s "{output.ids}"
        test -s "{output.smorfs_gff3}"
        """


rule tx_to_genome_gtf:
    input:
        sample_gtf=f"{OUTDIR}/{{sample}}/stringtie/{{sample}}.gtf",
        smorfs_gff3=f"{OUTDIR}/{{sample}}/smorfs/{{sample}}.smorfs.gff3",
        script=config["tx_to_genome_py"]
    output:
        gtf=f"{OUTDIR}/{{sample}}/shortstop/{{sample}}.smorfs_shortstop.gtf"
    threads: 1
    resources:
        mem_mb=8000
    shell:
        r"""
        set -euo pipefail
        mkdir -p "{OUTDIR}/{wildcards.sample}/shortstop"

        conda run --no-capture-output -n smORFs python "{input.script}" \
          --merged_gtf "{input.sample_gtf}" \
          --smorfs_gff3 "{input.smorfs_gff3}" \
          --out_gtf "{output.gtf}"

        test -s "{output.gtf}"
        """


rule shortstop_feature_extract:
    input:
        genome=config["genome_fa"],
        smorfs_gtf=f"{OUTDIR}/{{sample}}/shortstop/{{sample}}.smorfs_shortstop.gtf"
    output:
        done=f"{OUTDIR}/{{sample}}/shortstop/feature_extract.done"
    threads: config.get("threads_shortstop", 8)
    resources:
        mem_mb=16000
    shell:
        r"""
        set -euo pipefail

        cd "{OUTDIR}/{wildcards.sample}/shortstop"
        mkdir -p shortstop_output

        # testttttt
        unset PYTHONPATH
        unset LD_PRELOAD || true
        export CONDA_PREFIX="$(conda run -n smORFs python -c 'import os; print(os.environ["CONDA_PREFIX"])')"
        export LD_LIBRARY_PATH="$CONDA_PREFIX/lib:${{LD_LIBRARY_PATH:-}}"

        conda run --no-capture-output -n smORFs shortstop feature_extract \
          --genome "{input.genome}" \
          --putative_smorfs_gtf "{input.smorfs_gtf}" \
          --outdir shortstop_output \
          --threads {threads}

        touch "{output.done}"
        """


rule shortstop_predict:
    input:
        genome=config["genome_fa"],
        smorfs_gtf=f"{OUTDIR}/{{sample}}/shortstop/{{sample}}.smorfs_shortstop.gtf",
        feat_done=f"{OUTDIR}/{{sample}}/shortstop/feature_extract.done"
    output:
        done=f"{OUTDIR}/{{sample}}/shortstop/predict.done"
    threads: config.get("threads_shortstop", 8)
    resources:
        mem_mb=16000
    shell:
        r"""
        set -euo pipefail

        cd "{OUTDIR}/{wildcards.sample}/shortstop"
        mkdir -p shortstop_output

        # Ensure conda's C++ runtime is used (I was having a lot of "pandas" and GLIBCXX_* errors)
        export CONDA_PREFIX="$(conda run -n smORFs python -c 'import os; print(os.environ["CONDA_PREFIX"])')"
        export LD_LIBRARY_PATH="$CONDA_PREFIX/lib:${{LD_LIBRARY_PATH:-}}"

        conda run --no-capture-output -n smORFs shortstop predict \
          --genome "{input.genome}" \
          --putative_smorfs_gtf "{input.smorfs_gtf}" \
          --outdir shortstop_output \
          --threads {threads}

        touch "{output.done}"
        """


PRED_CSV = config.get("pred_csv", "sams.csv") # default sams.csv, but can be changed in c

rule merge_shortstop_output:
    input:
        predict_done=f"{OUTDIR}/{{sample}}/shortstop/predict.done",
        feat_done=f"{OUTDIR}/{{sample}}/shortstop/feature_extract.done",
        script=lambda wc: config["merge_script"]
    output:
        merged=f"{MERGED_DIR}/{{sample}}.merged.csv"
    threads: 1
    resources:
        mem_mb=8000
    params:
        root=OUTDIR,
        outdir=MERGED_DIR,
        pred_csv=PRED_CSV,
        min_prob=config.get("min_prob", None)
    shell:
        r"""
        set -euo pipefail
        mkdir -p "{params.outdir}"
        
        MINPROB_ARGS=""
        if [ "{params.min_prob}" != "None" ] && [ -n "{params.min_prob}" ]; then
          MINPROB_ARGS="--min_prob {params.min_prob}"
        fi

        conda run --no-capture-output -n smORFs python "{input.script}" \
          --root "{params.root}" \
          --outdir "{params.outdir}" \
          --samples "{wildcards.sample}" \
          $MINPROB_ARGS

        test -s "{output.merged}"
        """


rule aggregate_smorfs_by_locus:
    input:
        merged_csvs=expand(f"{MERGED_DIR}/{{sample}}.merged.csv", sample=SAMPLES),
        script=lambda wc: config["aggregate_script"]
    output:
        all_loci=f"{COHORT_PREFIX}.all_loci.csv",
        shared=f"{COHORT_PREFIX}.shared_ge{MIN_PATIENTS}.csv"
    threads: 1
    resources:
        mem_mb=12000
    params:
        merged_dir=MERGED_DIR,
        out_prefix=COHORT_PREFIX,
        min_patients=MIN_PATIENTS
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname "{params.out_prefix}")"

        conda run --no-capture-output -n smORFs python "{input.script}" \
          --merged_dir "{params.merged_dir}" \
          --out_prefix "{params.out_prefix}" \
          --min_patients {params.min_patients}

        test -s "{output.all_loci}"
        test -s "{output.shared}"
        """
