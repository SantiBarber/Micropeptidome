# Paths
units_csv: "units.csv"
cohort_prefix: "Liver_summary"
genome_fa: "/storage/scratch01/groups/md/microproteins/Microproteins_pipeline/Workdir/GRCh38.primary_assembly.genome.fa"
gencode_gtf: "/storage/scratch01/groups/md/microproteins/Microproteins_pipeline/Workdir/gencode.v38.primary_assembly.annotation.gtf"
ensembl_gtf: "/storage/scratch01/groups/md/microproteins/Microproteins_pipeline/Workdir/ensemlb_hg38_filtered.gtf"

# Helper scripts
filter_smorf_pep_py: "scripts/filter_smorf_pep.py"
tx_to_genome_py: "scripts/smorfs_transcript_to_genome_gtf.py"
merge_script: "scripts/merge_shortstop_output.py"
aggregate_script: "scripts/aggregate_smorfs_by_locus.py"
make_smorf_rsem_ref_script: "scripts/make_smorf_rsem_ref_from_locus_summary.py"
add_rsem_tpms_script: "scripts/add_rsem_tpms_to_locus_summary.py"
blastp_append_script: "scripts/blastp_append_human_homology.py"

# Output directories
outdir: "results"
star_index_dir: "results/STAR_index"
merged_dir: "results/merged_per_sample"
rsem_dir: "results/results_rsem_smorf"  

# RSEM
rsem_strandedness: "none"

# aggregation
min_patients: 2

# Threads
threads_stringtie: 2
threads_shortstop: 2
threads_transdecoder: 2  # TransDecoder itself doesn't parallelize much, but kept for resource planning

# smORF filter
min_aa: 10
max_aa: 150
pred_csv: "sams.csv" # this is ALL SAMs, but we can also use "sam_secreted.csv" or "sam_intracellular.csv" 

# BLASTP (human proteome homology)
human_proteome_fa: "/storage/scratch01/groups/md/microproteins/Microproteins_pipeline/Workdir/human_proteome.faa"
human_blastdb_prefix: "/storage/scratch01/groups/md/microproteins/Microproteins_pipeline/Workdir/human_proteome"  # where DB files will be created and with what prefix
